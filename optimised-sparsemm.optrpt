Intel(R) Advisor can now assist with vectorization and show optimization
  report messages with your source code.
See "https://software.intel.com/en-us/intel-advisor-xe" for details.

Intel(R) C Intel(R) 64 Compiler for applications running on Intel(R) 64, Version 19.0.0.117 Build 20180804

Compiler options: -g -O3 -qopt-report=5 -qopt-report-phase=vec -march=native -D_GNU_SOURCE -c -o optimised-sparsemm.o

Begin optimization report for: checkA(const COO, const int *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(31,3)
   remark #15382: vectorization support: call to function printf(const char *, ...) cannot be vectorized   [ optimised-sparsemm.c(40,7) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed ANTI dependence between Ams[outI] (32:18) and call:printf(const char *, ...) (40:7)

   LOOP BEGIN at optimised-sparsemm.c(36,5)
      remark #15382: vectorization support: call to function printf(const char *, ...) cannot be vectorized   [ optimised-sparsemm.c(40,7) ]
      remark #15344: loop was not vectorized: vector dependence prevents vectorization
   LOOP END
LOOP END
===========================================================================

Begin optimization report for: checkB(const COO, const int *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(52,3)
   remark #15382: vectorization support: call to function printf(const char *, ...) cannot be vectorized   [ optimised-sparsemm.c(61,7) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed ANTI dependence between Bns[outJ] (53:18) and call:printf(const char *, ...) (61:7)

   LOOP BEGIN at optimised-sparsemm.c(57,5)
      remark #15382: vectorization support: call to function printf(const char *, ...) cannot be vectorized   [ optimised-sparsemm.c(61,7) ]
      remark #15344: loop was not vectorized: vector dependence prevents vectorization
   LOOP END
LOOP END
===========================================================================

Begin optimization report for: optimised_sparsemm(const COO, const COO, COO *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(98,3)
   remark #15389: vectorization support: reference B->coords->i[b_entry_index] has unaligned access   [ optimised-sparsemm.c(99,34) ]
   remark #15388: vectorization support: reference B->data[b_entry_index] has aligned access   [ optimised-sparsemm.c(101,37) ]
   remark #15381: vectorization support: unaligned access used inside loop body
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->i[b_entry_index]>, stride is 4   [ optimised-sparsemm.c(99,5) ]
   remark #15328: vectorization support: non-unit strided load was emulated for the variable <B->coords->i[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(99,34) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->j[b_entry_index]>, stride is 4   [ optimised-sparsemm.c(100,5) ]
   remark #15328: vectorization support: non-unit strided load was emulated for the variable <B->coords->j[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(100,34) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->data[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(101,5) ]
   remark #15305: vectorization support: vector length 16
   remark #15300: LOOP WAS VECTORIZED
   remark #15448: unmasked aligned unit stride loads: 1 
   remark #15452: unmasked strided loads: 2 
   remark #15453: unmasked strided stores: 3 
   remark #15475: --- begin vector cost summary ---
   remark #15476: scalar cost: 14 
   remark #15477: vector cost: 7.930 
   remark #15478: estimated potential speedup: 1.710 
   remark #15488: --- end vector cost summary ---
LOOP END

LOOP BEGIN at optimised-sparsemm.c(98,3)
<Remainder loop for vectorization>
   remark #15388: vectorization support: reference B->coords->i[b_entry_index] has aligned access   [ optimised-sparsemm.c(99,34) ]
   remark #15388: vectorization support: reference B->data[b_entry_index] has aligned access   [ optimised-sparsemm.c(101,37) ]
   remark #15305: vectorization support: vector length 4
   remark #15309: vectorization support: normalized vectorization overhead 0.250
   remark #15301: REMAINDER LOOP WAS VECTORIZED
   remark #15448: unmasked aligned unit stride loads: 1 
   remark #15452: unmasked strided loads: 2 
   remark #15453: unmasked strided stores: 3 
   remark #15475: --- begin vector cost summary ---
   remark #15476: scalar cost: 14 
   remark #15477: vector cost: 7.930 
   remark #15478: estimated potential speedup: 1.710 
   remark #15488: --- end vector cost summary ---
LOOP END

LOOP BEGIN at optimised-sparsemm.c(98,3)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at optimised-sparsemm.c(133,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at optimised-sparsemm.c(133,5)
      remark #15388: vectorization support: reference Ams[AMIndex+1] has aligned access   [ optimised-sparsemm.c(134,7) ]
      remark #15305: vectorization support: vector length 8
      remark #15309: vectorization support: normalized vectorization overhead 0.250
      remark #15300: LOOP WAS VECTORIZED
      remark #15449: unmasked aligned unit stride stores: 1 
      remark #15475: --- begin vector cost summary ---
      remark #15476: scalar cost: 4 
      remark #15477: vector cost: 0.500 
      remark #15478: estimated potential speedup: 7.380 
      remark #15488: --- end vector cost summary ---
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(133,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(147,3)
   remark #15382: vectorization support: call to function _?1memcpy cannot be vectorized   [ optimised-sparsemm.c(158,9) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed OUTPUT dependence between Ams[AMIndex+1] (149:7) and Ams[AMIndex+1] (178:7)
   remark #15346: vector dependence: assumed OUTPUT dependence between Ams[AMIndex+1] (178:7) and Ams[AMIndex+1] (149:7)

   LOOP BEGIN at optimised-sparsemm.c(158,9)
      remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

      LOOP BEGIN at optimised-sparsemm.c(158,9)
      <Multiversioned v2>
         remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
      LOOP END

      LOOP BEGIN at optimised-sparsemm.c(158,9)
      <Remainder, Multiversioned v2>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(187,3)
   remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

   LOOP BEGIN at optimised-sparsemm.c(187,3)
   <Multiversioned v2>
      remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(187,3)
   <Remainder, Multiversioned v2>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(209,5)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at optimised-sparsemm.c(209,5)
      remark #15388: vectorization support: reference Bns[BNIndex+1] has aligned access   [ optimised-sparsemm.c(210,7) ]
      remark #15305: vectorization support: vector length 8
      remark #15309: vectorization support: normalized vectorization overhead 0.250
      remark #15300: LOOP WAS VECTORIZED
      remark #15449: unmasked aligned unit stride stores: 1 
      remark #15475: --- begin vector cost summary ---
      remark #15476: scalar cost: 4 
      remark #15477: vector cost: 0.500 
      remark #15478: estimated potential speedup: 7.380 
      remark #15488: --- end vector cost summary ---
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(209,5)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(221,3)
   remark #15382: vectorization support: call to function _?1memcpy cannot be vectorized   [ optimised-sparsemm.c(232,9) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed OUTPUT dependence between Bns[BNIndex+1] (223:7) and Bns[BNIndex+1] (253:7)
   remark #15346: vector dependence: assumed OUTPUT dependence between Bns[BNIndex+1] (253:7) and Bns[BNIndex+1] (223:7)

   LOOP BEGIN at optimised-sparsemm.c(232,9)
      remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

      LOOP BEGIN at optimised-sparsemm.c(232,9)
      <Multiversioned v2>
         remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
      LOOP END

      LOOP BEGIN at optimised-sparsemm.c(232,9)
      <Remainder, Multiversioned v2>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(261,3)
   remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

   LOOP BEGIN at optimised-sparsemm.c(261,3)
   <Multiversioned v2>
      remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(261,3)
   <Remainder, Multiversioned v2>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(430,3) inlined into optimised-sparsemm.c(271,25)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

   LOOP BEGIN at optimised-sparsemm.c(432,5) inlined into optimised-sparsemm.c(271,25)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

      LOOP BEGIN at optimised-sparsemm.c(445,7) inlined into optimised-sparsemm.c(271,25)
         remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(292,3)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed ANTI dependence between A->coords->j[rowIndex] (309:9) and *C->coords->j[outputNNZ] (325:11)
   remark #15346: vector dependence: assumed FLOW dependence between *C->coords->j[outputNNZ] (325:11) and A->coords->j[rowIndex] (309:9)

   LOOP BEGIN at optimised-sparsemm.c(294,5)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization
      remark #15346: vector dependence: assumed ANTI dependence between A->coords->j[rowIndex] (309:9) and *C->coords->j[outputNNZ] (325:11)
      remark #15346: vector dependence: assumed FLOW dependence between *C->coords->j[outputNNZ] (325:11) and A->coords->j[rowIndex] (309:9)

      LOOP BEGIN at optimised-sparsemm.c(308,7)
         remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
      LOOP END
   LOOP END
LOOP END
===========================================================================

Begin optimization report for: getNonZeroes(const COO, int, struct _dataEntry *, const int *, const int *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(430,3)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

   LOOP BEGIN at optimised-sparsemm.c(432,5)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

      LOOP BEGIN at optimised-sparsemm.c(445,7)
         remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
      LOOP END
   LOOP END
LOOP END
===========================================================================

Begin optimization report for: addThreeMatrices(COO, COO, COO, COO)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(501,20)
   remark #15522: loop was not vectorized: loop control flow is too complex. Try using canonical loop form from OpenMP specification
LOOP END
===========================================================================

Begin optimization report for: optimised_sparsemm_sum(const COO, const COO, const COO, const COO, const COO, const COO, COO *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(98,3) inlined into optimised-sparsemm.c(697,3)
   remark #15389: vectorization support: reference H->coords->i[b_entry_index] has unaligned access   [ optimised-sparsemm.c(99,34) ]
   remark #15388: vectorization support: reference H->data[b_entry_index] has aligned access   [ optimised-sparsemm.c(101,37) ]
   remark #15381: vectorization support: unaligned access used inside loop body
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->i[b_entry_index]>, stride is 4   [ optimised-sparsemm.c(99,5) ]
   remark #15328: vectorization support: non-unit strided load was emulated for the variable <H->coords->i[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(99,34) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->j[b_entry_index]>, stride is 4   [ optimised-sparsemm.c(100,5) ]
   remark #15328: vectorization support: non-unit strided load was emulated for the variable <H->coords->j[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(100,34) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <B_entries->data[b_entry_index]>, stride is 2   [ optimised-sparsemm.c(101,5) ]
   remark #15305: vectorization support: vector length 16
   remark #15300: LOOP WAS VECTORIZED
   remark #15448: unmasked aligned unit stride loads: 1 
   remark #15452: unmasked strided loads: 2 
   remark #15453: unmasked strided stores: 3 
   remark #15475: --- begin vector cost summary ---
   remark #15476: scalar cost: 14 
   remark #15477: vector cost: 7.930 
   remark #15478: estimated potential speedup: 1.710 
   remark #15488: --- end vector cost summary ---
LOOP END

LOOP BEGIN at optimised-sparsemm.c(98,3) inlined into optimised-sparsemm.c(697,3)
<Remainder loop for vectorization>
   remark #15388: vectorization support: reference H->coords->i[b_entry_index] has aligned access   [ optimised-sparsemm.c(99,34) ]
   remark #15388: vectorization support: reference H->data[b_entry_index] has aligned access   [ optimised-sparsemm.c(101,37) ]
   remark #15305: vectorization support: vector length 4
   remark #15309: vectorization support: normalized vectorization overhead 0.250
   remark #15301: REMAINDER LOOP WAS VECTORIZED
   remark #15448: unmasked aligned unit stride loads: 1 
   remark #15452: unmasked strided loads: 2 
   remark #15453: unmasked strided stores: 3 
   remark #15475: --- begin vector cost summary ---
   remark #15476: scalar cost: 14 
   remark #15477: vector cost: 7.930 
   remark #15478: estimated potential speedup: 1.710 
   remark #15488: --- end vector cost summary ---
LOOP END

LOOP BEGIN at optimised-sparsemm.c(98,3) inlined into optimised-sparsemm.c(697,3)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at optimised-sparsemm.c(133,5) inlined into optimised-sparsemm.c(697,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at optimised-sparsemm.c(133,5) inlined into optimised-sparsemm.c(697,3)
      remark #15388: vectorization support: reference Ams[AMIndex+1] has aligned access   [ optimised-sparsemm.c(134,7) ]
      remark #15305: vectorization support: vector length 8
      remark #15309: vectorization support: normalized vectorization overhead 0.250
      remark #15300: LOOP WAS VECTORIZED
      remark #15449: unmasked aligned unit stride stores: 1 
      remark #15475: --- begin vector cost summary ---
      remark #15476: scalar cost: 4 
      remark #15477: vector cost: 0.500 
      remark #15478: estimated potential speedup: 7.380 
      remark #15488: --- end vector cost summary ---
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(133,5) inlined into optimised-sparsemm.c(697,3)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(147,3) inlined into optimised-sparsemm.c(697,3)
   remark #15382: vectorization support: call to function _?1memcpy cannot be vectorized   [ optimised-sparsemm.c(158,9) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed OUTPUT dependence between Ams[AMIndex+1] (149:7) and Ams[AMIndex+1] (178:7)
   remark #15346: vector dependence: assumed OUTPUT dependence between Ams[AMIndex+1] (178:7) and Ams[AMIndex+1] (149:7)

   LOOP BEGIN at optimised-sparsemm.c(158,9) inlined into optimised-sparsemm.c(697,3)
      remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

      LOOP BEGIN at optimised-sparsemm.c(158,9) inlined into optimised-sparsemm.c(697,3)
      <Multiversioned v2>
         remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
      LOOP END

      LOOP BEGIN at optimised-sparsemm.c(158,9) inlined into optimised-sparsemm.c(697,3)
      <Remainder, Multiversioned v2>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(187,3) inlined into optimised-sparsemm.c(697,3)
   remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

   LOOP BEGIN at optimised-sparsemm.c(187,3) inlined into optimised-sparsemm.c(697,3)
   <Multiversioned v2>
      remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(187,3) inlined into optimised-sparsemm.c(697,3)
   <Remainder, Multiversioned v2>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(209,5) inlined into optimised-sparsemm.c(697,3)
   remark #15542: loop was not vectorized: inner loop was already vectorized

   LOOP BEGIN at optimised-sparsemm.c(209,5) inlined into optimised-sparsemm.c(697,3)
      remark #15388: vectorization support: reference Bns[BNIndex+1] has aligned access   [ optimised-sparsemm.c(210,7) ]
      remark #15305: vectorization support: vector length 8
      remark #15309: vectorization support: normalized vectorization overhead 0.250
      remark #15300: LOOP WAS VECTORIZED
      remark #15449: unmasked aligned unit stride stores: 1 
      remark #15475: --- begin vector cost summary ---
      remark #15476: scalar cost: 4 
      remark #15477: vector cost: 0.500 
      remark #15478: estimated potential speedup: 7.380 
      remark #15488: --- end vector cost summary ---
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(209,5) inlined into optimised-sparsemm.c(697,3)
   <Remainder loop for vectorization>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(221,3) inlined into optimised-sparsemm.c(697,3)
   remark #15382: vectorization support: call to function _?1memcpy cannot be vectorized   [ optimised-sparsemm.c(232,9) ]
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed OUTPUT dependence between Bns[BNIndex+1] (223:7) and Bns[BNIndex+1] (253:7)
   remark #15346: vector dependence: assumed OUTPUT dependence between Bns[BNIndex+1] (253:7) and Bns[BNIndex+1] (223:7)

   LOOP BEGIN at optimised-sparsemm.c(232,9) inlined into optimised-sparsemm.c(697,3)
      remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

      LOOP BEGIN at optimised-sparsemm.c(232,9) inlined into optimised-sparsemm.c(697,3)
      <Multiversioned v2>
         remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
      LOOP END

      LOOP BEGIN at optimised-sparsemm.c(232,9) inlined into optimised-sparsemm.c(697,3)
      <Remainder, Multiversioned v2>
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(261,3) inlined into optimised-sparsemm.c(697,3)
   remark #15398: loop was not vectorized: loop was transformed to memset or memcpy

   LOOP BEGIN at optimised-sparsemm.c(261,3) inlined into optimised-sparsemm.c(697,3)
   <Multiversioned v2>
      remark #15304: loop was not vectorized: non-vectorizable loop instance from multiversioning
   LOOP END

   LOOP BEGIN at optimised-sparsemm.c(261,3) inlined into optimised-sparsemm.c(697,3)
   <Remainder, Multiversioned v2>
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(430,3) inlined into optimised-sparsemm.c(697,3)
   remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

   LOOP BEGIN at optimised-sparsemm.c(432,5) inlined into optimised-sparsemm.c(697,3)
      remark #15541: outer loop was not auto-vectorized: consider using SIMD directive   [ optimised-sparsemm.c(445,7) ]

      LOOP BEGIN at optimised-sparsemm.c(445,7) inlined into optimised-sparsemm.c(697,3)
         remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
      LOOP END
   LOOP END
LOOP END

LOOP BEGIN at optimised-sparsemm.c(292,3) inlined into optimised-sparsemm.c(697,3)
   remark #15344: loop was not vectorized: vector dependence prevents vectorization
   remark #15346: vector dependence: assumed ANTI dependence between G->coords->j[rowIndex] (309:9) and *O->coords->j[outputNNZ] (325:11)
   remark #15346: vector dependence: assumed FLOW dependence between *O->coords->j[outputNNZ] (325:11) and G->coords->j[rowIndex] (309:9)

   LOOP BEGIN at optimised-sparsemm.c(294,5) inlined into optimised-sparsemm.c(697,3)
      remark #15344: loop was not vectorized: vector dependence prevents vectorization
      remark #15346: vector dependence: assumed ANTI dependence between G->coords->j[rowIndex] (309:9) and *O->coords->j[outputNNZ] (325:11)
      remark #15346: vector dependence: assumed FLOW dependence between *O->coords->j[outputNNZ] (325:11) and G->coords->j[rowIndex] (309:9)

      LOOP BEGIN at optimised-sparsemm.c(308,7) inlined into optimised-sparsemm.c(697,3)
         remark #15521: loop was not vectorized: loop control variable was not identified. Explicitly compute the iteration count before executing the loop or try using canonical loop form from OpenMP specification
      LOOP END
   LOOP END
LOOP END
===========================================================================

Begin optimization report for: addThreeMatrices2(COO, COO, COO, COO *)

    Report from: Vector optimizations [vec]


LOOP BEGIN at optimised-sparsemm.c(583,3)
   remark #15520: loop was not vectorized: loop with multiple exits cannot be vectorized unless it meets search loop idiom criteria   [ optimised-sparsemm.c(587,7) ]
LOOP END

LOOP BEGIN at optimised-sparsemm.c(657,3)
   remark #15388: vectorization support: reference *out->coords->i[index] has aligned access   [ optimised-sparsemm.c(658,7) ]
   remark #15388: vectorization support: reference outIs[index] has aligned access   [ optimised-sparsemm.c(658,33) ]
   remark #15388: vectorization support: reference outJs[index] has aligned access   [ optimised-sparsemm.c(659,33) ]
   remark #15388: vectorization support: reference *out->data[index] has aligned access   [ optimised-sparsemm.c(660,7) ]
   remark #15388: vectorization support: reference additions[index] has aligned access   [ optimised-sparsemm.c(660,39) ]
   remark #15388: vectorization support: reference additions[index] has aligned access   [ optimised-sparsemm.c(660,39) ]
   remark #15388: vectorization support: reference additions[index] has aligned access   [ optimised-sparsemm.c(660,39) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <*out->coords->i[index]>, stride is 2   [ optimised-sparsemm.c(658,7) ]
   remark #15329: vectorization support: non-unit strided store was emulated for the variable <*out->coords->j[index]>, stride is 2   [ optimised-sparsemm.c(659,7) ]
   remark #15328: vectorization support: indirect load was emulated for the variable <additions[index][0]>, 64-bit indexed, part of address is read from memory   [ optimised-sparsemm.c(533,12) ]
   remark #15328: vectorization support: indirect load was emulated for the variable <additions[index][1]>, 64-bit indexed, part of address is read from memory   [ optimised-sparsemm.c(533,21) ]
   remark #15328: vectorization support: indirect load was emulated for the variable <additions[index][2]>, 64-bit indexed, part of address is read from memory   [ optimised-sparsemm.c(533,30) ]
   remark #15305: vectorization support: vector length 2
   remark #15399: vectorization support: unroll factor set to 4
   remark #15300: LOOP WAS VECTORIZED
   remark #15448: unmasked aligned unit stride loads: 3 
   remark #15449: unmasked aligned unit stride stores: 1 
   remark #15450: unmasked unaligned unit stride loads: 2 
   remark #15453: unmasked strided stores: 2 
   remark #15462: unmasked indexed (or gather) loads: 3 
   remark #15475: --- begin vector cost summary ---
   remark #15476: scalar cost: 20 
   remark #15477: vector cost: 19.000 
   remark #15478: estimated potential speedup: 1.050 
   remark #15488: --- end vector cost summary ---
LOOP END

LOOP BEGIN at optimised-sparsemm.c(657,3)
<Remainder loop for vectorization>
LOOP END

LOOP BEGIN at optimised-sparsemm.c(665,3)
   remark #15527: loop was not vectorized: function call to free(const void *) cannot be vectorized   [ optimised-sparsemm.c(666,5) ]
LOOP END


Non-optimizable loops:


LOOP BEGIN at optimised-sparsemm.c(647,5)
   remark #15522: loop was not vectorized: loop control flow is too complex. Try using canonical loop form from OpenMP specification
LOOP END
===========================================================================
